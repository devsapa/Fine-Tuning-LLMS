{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91e7017-51a7-421c-af20-5c12332fb43f",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "\n",
    "\n",
    "# <a name=\"0\">MLU LLM Workshop </a>\n",
    "## <a name=\"0\">Lab 4: Deploy a Pretrained Model </a>\n",
    "    \n",
    "In this notebook, we will deploy a large languages model (LLM) that we finetuned in the last notebook. Specifically, we will use [DJL (Deep Java Library)](https://djl.ai/), a machine learning library that provides a seamless interface for developing and deploying deep learning models, with support for Python and other programming languages. DJL is designed to be framework-agnostic, which means it provides a unified interface and abstractions for working with various deep learning frameworks, such as TensorFlow and PyTorch. It allows developers to switch between different frameworks without having to make extensive code changes. DJL enables easy deployment of trained models into production environments. It offers integrations with popular deployment platforms such as Amazon SageMaker, making it easier to serve models at scale.\n",
    "    \n",
    "\n",
    "In this notebook, we will cover the following key aspects:\n",
    "\n",
    "1. <a href=\"#1\">Install and import libraries</a>\n",
    "2. <a href=\"#2\">Overview of deployment parameters</a>\n",
    "3. <a href=\"#3\">Instantiate SageMaker parameters</a>\n",
    "4. <a href=\"#4\">Create the model artifact</a>\n",
    "5. <a href=\"#5\">Produce the inference script</a>\n",
    "6. <a href=\"6\">Upload the model artifact to S3</a>\n",
    "7. <a href=\"#5\">Deploy the finetuned LLM</a>\n",
    "8. <a href=\"#6\">Inference via the deployed LLM</a>\n",
    "9. <a href=\"#7\">Quizzes</a>\n",
    "\n",
    "Please work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code.\n",
    "\n",
    "---\n",
    "\n",
    "You will be presented with two kinds of exercises throughout the notebook: activities and challenges. <br/>\n",
    "\n",
    "| <img style=\"float: center;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>| <img style=\"float: center;\" src=\"./images/challenge.png\" alt=\"Challenge\" width=\"125\"/>|\n",
    "| --- | --- |\n",
    "|<p style=\"text-align:center;\">No coding is needed for an activity. You try to understand a concept, <br/>answer questions, or run a code cell.</p> |<p style=\"text-align:center;\">Challenges are where you test your understanding by taking a short quiz.</p> |\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e914fd-da42-40b5-b5af-0bb809145a5e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a name=\"1\">Install and Import libraries</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "First, let's install and import the necessary libraries for deployment, including the `sagemaker` library and the `Boto3` library, the AWS Python SDK. If you haven't install the packages, uncomment the below line and install them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56af2875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install -U sagemaker --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7b2b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sagemaker.djl_inference\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import image_uris\n",
    "from sagemaker import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc371ee7-ca02-46b1-b9ac-0723b20dfa05",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <a name=\"2\">Overview of deployment parameters</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To deploy using the SageMaker Python SDK with the DJL, we will need to instantiate `Model` class with the following parameters:\n",
    "```{python}\n",
    "model = Model(\n",
    "    image_uri,\n",
    "    model_data=...,\n",
    "    predictor_cls=...,\n",
    "    role=aws_role\n",
    ")\n",
    "```\n",
    "- `image_uri`: The Docker image URI representing the deep learning framework and version to be used.\n",
    "- `model_data`: The location of the finetuned LLM model artifact in an S3 bucket. It specifies the path to the TAR GZ file containing the model's parameters, architecture, and any necessary artifacts.\n",
    "- `predictor_cls`: This is just a \"json in json out\" predictor, nothing DJL related, check more details at [sagemaker.djl_inference.DJLPredictor](https://sagemaker.readthedocs.io/en/stable/frameworks/djl/sagemaker.djl_inference.html#djlpredictor).\n",
    "- `role`: The AWS Identity and Access Management (IAM) role ARN that provides necessary permissions to access resources like the S3 bucket containing the model data.\n",
    "\n",
    "---\n",
    "### <a name=\"3\">Instantiate SageMaker parameters</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's initialize a SageMaker session and retrieve information related to the AWS environment such as SageMaker role and AWS region. We also specify the image URI for a specific version of the \"djl-deepspeed\" framework using the SageMaker session's region. The image URI is a unique identifier for a specific Docker container image that can be used in various AWS services, such as Amazon SageMaker or Elastic Container Registry (ECR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e239c028-bca0-4a01-9c5e-a97408525659",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker_session:  <sagemaker.session.Session object at 0x7f32cfe33a30>\n",
      "aws_role:  arn:aws:iam::757420736997:role/WorkshopEndtoEnd\n",
      "aws_region:  us-east-1\n",
      "image_uri:  763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.22.1-deepspeed0.9.2-cu118\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = Session()\n",
    "print(\"sagemaker_session: \", sagemaker_session)\n",
    "\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "print(\"aws_role: \", aws_role)\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "print(\"aws_region: \", aws_region)\n",
    "\n",
    "image_uri = image_uris.retrieve(framework=\"djl-deepspeed\",\n",
    "                                version=\"0.22.1\",\n",
    "                                region=sagemaker_session._region_name)\n",
    "print(\"image_uri: \", image_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e70e1-31d7-4efd-8ca1-6c230ad0f696",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### <a name=\"4\">Create the model artifact</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To upload the model artifact in the S3 bucket, we need to create TAR GZ file containing the model's parameters. First, we create a directory named `lora_model` and a subdirectory named `dolly-3b-lora`. The \"-p\" option ensures that the command creates any intermediate directories if they don't exist. Then, we copy the lora checkpoints `adapter_model.bin` and `adapter_config.json` to `dolly-3b-lora`. The base dolly model will be downloaded at runtime from huggingface hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016d06d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf lora_model\n",
    "mkdir -p lora_model\n",
    "mkdir -p lora_model/dolly-3b-lora\n",
    "cp dolly-3b-lora/adapter_config.json lora_model/dolly-3b-lora/\n",
    "cp dolly-3b-lora/adapter_model.bin lora_model/dolly-3b-lora/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90170730-80fb-45a6-aed4-6e089b5a8e31",
   "metadata": {},
   "source": [
    "Next, we need to set the [DJL Serving configuration options](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-configuration.html) in `serving.properties`. The jupyter `%%writefile` magic command enables us to write the following content to a file named \"lora_model/serving.properties\".\n",
    "- `engine=Python`: This line specifies the engine used for serving.\n",
    "- `option.entryPoint=model.py`: This line specifies the entry point for the serving process, which is set to \"model.py\". \n",
    "- `option.adapter_checkpoint=dolly-3b-lora`: This line sets the checkpoint for the adapter to \"dolly-3b-lora\". A checkpoint typically represents the saved state of a model or its parameters.\n",
    "- `option.adapter_name=dolly-lora`: This line sets the name of the adapter to \"dolly-lora\", a component that helps interface between the model and the serving infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c37aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lora_model/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile lora_model/serving.properties\n",
    "engine=Python\n",
    "option.entryPoint=model.py\n",
    "option.adapter_checkpoint=dolly-3b-lora\n",
    "option.adapter_name=dolly-lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999ac727-6837-4d2a-b02b-0e73fea31df2",
   "metadata": {},
   "source": [
    "Another file we need in the the model artifact is the environment requirement file. Let's use the same `requirements.txt` file from the lab folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83af3874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp requirements.txt lora_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79417d1a-87cc-4dcb-994b-09125178a0c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <a name=\"5\">Produce the inference script</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Similar to the finetuning notebook, we have defined a text generation pipeline for inference. The code is provided in `mlu_utils/deployment_model.py`. \n",
    "\n",
    "We save these inference functions to `lora_model/model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443c2181-20b3-4de4-adce-a0a7baa99cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp mlu_utils/deployment_model.py lora_model/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470648f-eec2-4d08-8e2e-4b0db11dacfa",
   "metadata": {},
   "source": [
    "---\n",
    "### <a name=\"6\">Upload the model artifact to S3</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's create a compressed tarball archive of the \"lora_model\" directory and saves it as \"lora_model.tar.gz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb037303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_model/\n",
      "lora_model/model.py\n",
      "lora_model/dolly-3b-lora/\n",
      "lora_model/dolly-3b-lora/adapter_model.bin\n",
      "lora_model/dolly-3b-lora/adapter_config.json\n",
      "lora_model/serving.properties\n",
      "lora_model/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tar -cvzf lora_model.tar.gz lora_model/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1653884e-8b68-43e2-a279-5c2fe8e08ae1",
   "metadata": {},
   "source": [
    "Create a bucket with your desired name and add it to the `mybucket` variable.\n",
    "If the S3 bucket is not created, an existing one would be selected.\n",
    "\n",
    "We upload the \"lora_model.tar.gz\" file to the specified S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2065c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Set the bucket\n",
    "mybucket=sagemaker_session.default_bucket()\n",
    "    \n",
    "response = s3_client.upload_file(\"lora_model.tar.gz\", mybucket, \"lora_model.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce81a5c-bb62-4e5b-950f-91852857a84a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### <a name=\"7\">Deploy the finetuned LLM</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now it's the time to deploy the finetuned LLM using SageMaker Python SDK. The SageMaker Python SDK `Model` class is instantiated with the following parameters:\n",
    "\n",
    "- `image_uri`: The Docker image URI representing the deep learning framework and version to be used.\n",
    "- `model_data`: The location of the finetuned LLM model artifact in an S3 bucket. It specifies the path to the TAR GZ file containing the model's parameters, architecture, and any necessary artifacts.\n",
    "- `predictor_cls`: This is just a \"json in json out\" predictor, nothing DJL related, check more details at [sagemaker.djl_inference.DJLPredictor](https://sagemaker.readthedocs.io/en/stable/frameworks/djl/sagemaker.djl_inference.html#djlpredictor).\n",
    "- `role`: The AWS Identity and Access Management (IAM) role ARN that provides necessary permissions to access resources like the S3 bucket containing the model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc952785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data=\"s3://{}/lora_model.tar.gz\".format(mybucket)\n",
    "\n",
    "model = Model(image_uri=image_uri,\n",
    "              model_data=model_data,\n",
    "              predictor_cls=sagemaker.djl_inference.DJLPredictor,\n",
    "              role=aws_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3fcdb-d9df-493d-bfa4-32867d4aed5d",
   "metadata": {},
   "source": [
    "Note: **The deployment should finish within 10 minutes. If it took longer than that, your endpoint may be failed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "899aba10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!CPU times: user 141 ms, sys: 13.6 ms, total: 155 ms\n",
      "Wall time: 6min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = model.deploy(1, \"ml.g4dn.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80029614-9865-4dba-9664-38b8d7cd4461",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a name=\"8\">Inference via the deployed model</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now let's test our inference endpoint with [predictor.predict](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html#sagemaker.predictor.Predictor.predict)!\n",
    "\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h2><i>Try it Yourself!</i></h2>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">Try different prompts and observe the quality of responses generated by the deployed model.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c95a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = predictor.predict({\"inputs\": \"What solutions come pre-built with Amazon SageMaker JumpStart?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "438c2ae3-37e2-4737-9131-7d5795b1b67c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amazon SageMaker JumpStart includes pre-built solutions for ML model training, model deployment, and model monitoring. You can choose from a variety of pre-built solutions, including ML model training, model deployment, and model monitoring. You can also customize your solution to meet your business needs. For example, you can choose from a variety of ML model training solutions, such as Amazon SageMaker Training Manager, Amazon SageMaker Training Studio, and Amazon SageMaker Studio. You can also choose from a variety of model deployment solutions, such as Amazon SageMaker Model Deployment Manager, Amazon SageMaker Model Deployment Studio, and Amazon SageMaker Model Deployment Studio. You can choose from a variety of model monitoring solutions, such as Amazon SageMaker Model Monitoring Manager, Amazon SageMaker Model Monitoring Studio, and Amazon SageMaker Model Monitoring Studio. You can also choose from a variety of solutions for model deployment and model monitoring. You can also customize your solution to meet your business needs. For example,'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "991aa9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Amazon SageMaker JumpStart includes pre-built solutions for ML model training, model deployment, and model monitoring. You can choose from a variety of pre-built solutions, including ML model training, model deployment, and model monitoring. You can also customize your solution to meet your business needs. For example, you can choose from a variety of ML model training solutions, such as Amazon SageMaker Training Manager, Amazon SageMaker Training Studio, and Amazon SageMaker Studio. You can also choose from a variety of model deployment solutions, such as Amazon SageMaker Model Deployment Manager, Amazon SageMaker Model Deployment Studio, and Amazon SageMaker Model Deployment Studio. You can choose from a variety of model monitoring solutions, such as Amazon SageMaker Model Monitoring Manager, Amazon SageMaker Model Monitoring Studio, and Amazon SageMaker Model Monitoring Studio. You can also choose from a variety of solutions for model deployment and model monitoring. You can also customize your solution to meet your business needs. For example,"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d5a39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a name=\"9\">Cleaning up everything</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "After finishing this notebook let's be frugal and delete the model and the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf6e9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab8745c-9cca-43c5-a596-a46f360a56c6",
   "metadata": {},
   "source": [
    "Let's remove model artifacts to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15a2c71f-935e-4744-8109-b32c22481860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf lora_model*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b8174-8572-4d33-864b-07b429ff7ee1",
   "metadata": {},
   "source": [
    "### <a name=\"10\">Quizzes</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Well done on completing the lab! Now, it's time for a brief knowledge assessment.\n",
    "\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h2><i>Try it Yourself!</i></h2>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">Answer the following questions to test your understanding of deploying LLMs to an endpoint using Sagemaker.</p>\n",
    "    <br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "615c1baf-6777-4070-af56-13513af35be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>var Quiz=function(){\"use strict\";var M=document.createElement(\"style\");M.textContent=`.quiz-wrapper.svelte-fk6ar3{padding:1rem}.footer.svelte-fk6ar3{display:flex;align-items:center}h2.svelte-fk6ar3{font-size:1.5rem;margin-bottom:2rem;color:#232f3e}p.svelte-fk6ar3{font-size:16px}.options.svelte-fk6ar3{display:grid;grid-template-columns:repeat(2,50%);grid-template-rows:repeat(2,1fr);width:100%;margin:auto;justify-content:center}.mlu-quizquestion-option-button.svelte-fk6ar3{padding:1rem;margin:.5rem}.submit-button.svelte-fk6ar3{padding:1rem;margin:.5rem;width:90px;color:#fff;background-color:coral}.active.svelte-fk6ar3{background-color:#232f3e;color:#fff}.correct-answer.svelte-fk6ar3{background-color:green}.incorrect-answer.svelte-fk6ar3{background-color:red;text-decoration:line-through}.available.svelte-fk6ar3{pointer-events:none;opacity:.6}\n",
       "`,document.head.appendChild(M);function I(){}function P(e){return e()}function W(){return Object.create(null)}function O(e){e.forEach(P)}function X(e){return typeof e==\"function\"}function Z(e,t){return e!=e?t==t:e!==t||e&&typeof e==\"object\"||typeof e==\"function\"}function x(e){return Object.keys(e).length===0}function m(e,t){e.appendChild(t)}function j(e,t,n){e.insertBefore(t,n||null)}function z(e){e.parentNode&&e.parentNode.removeChild(e)}function ee(e,t){for(let n=0;n<e.length;n+=1)e[n]&&e[n].d(t)}function k(e){return document.createElement(e)}function A(e){return document.createTextNode(e)}function S(){return A(\" \")}function te(){return A(\"\")}function Y(e,t,n,r){return e.addEventListener(t,n,r),()=>e.removeEventListener(t,n,r)}function v(e,t,n){n==null?e.removeAttribute(t):e.getAttribute(t)!==n&&e.setAttribute(t,n)}function ne(e){return Array.from(e.childNodes)}function T(e,t){t=\"\"+t,e.wholeText!==t&&(e.data=t)}function p(e,t,n){e.classList[n?\"add\":\"remove\"](t)}let L;function N(e){L=e}const $=[],D=[],Q=[],F=[],re=Promise.resolve();let B=!1;function oe(){B||(B=!0,re.then(H))}function R(e){Q.push(e)}const G=new Set;let E=0;function H(){if(E!==0)return;const e=L;do{try{for(;E<$.length;){const t=$[E];E++,N(t),le(t.$$)}}catch(t){throw $.length=0,E=0,t}for(N(null),$.length=0,E=0;D.length;)D.pop()();for(let t=0;t<Q.length;t+=1){const n=Q[t];G.has(n)||(G.add(n),n())}Q.length=0}while($.length);for(;F.length;)F.pop()();B=!1,G.clear(),N(e)}function le(e){if(e.fragment!==null){e.update(),O(e.before_update);const t=e.dirty;e.dirty=[-1],e.fragment&&e.fragment.p(e.ctx,t),e.after_update.forEach(R)}}const ie=new Set;function se(e,t){e&&e.i&&(ie.delete(e),e.i(t))}function ce(e,t,n,r){const{fragment:l,after_update:i}=e.$$;l&&l.m(t,n),r||R(()=>{const s=e.$$.on_mount.map(P).filter(X);e.$$.on_destroy?e.$$.on_destroy.push(...s):O(s),e.$$.on_mount=[]}),i.forEach(R)}function fe(e,t){const n=e.$$;n.fragment!==null&&(O(n.on_destroy),n.fragment&&n.fragment.d(t),n.on_destroy=n.fragment=null,n.ctx=[])}function ue(e,t){e.$$.dirty[0]===-1&&($.push(e),oe(),e.$$.dirty.fill(0)),e.$$.dirty[t/31|0]|=1<<t%31}function ae(e,t,n,r,l,i,s,g=[-1]){const c=L;N(e);const o=e.$$={fragment:null,ctx:[],props:i,update:I,not_equal:l,bound:W(),on_mount:[],on_destroy:[],on_disconnect:[],before_update:[],after_update:[],context:new Map(t.context||(c?c.$$.context:[])),callbacks:W(),dirty:g,skip_bound:!1,root:t.target||c.$$.root};s&&s(o.root);let b=!1;if(o.ctx=n?n(e,t.props||{},(a,q,...y)=>{const h=y.length?y[0]:q;return o.ctx&&l(o.ctx[a],o.ctx[a]=h)&&(!o.skip_bound&&o.bound[a]&&o.bound[a](h),b&&ue(e,a)),q}):[],o.update(),b=!0,O(o.before_update),o.fragment=r?r(o.ctx):!1,t.target){if(t.hydrate){const a=ne(t.target);o.fragment&&o.fragment.l(a),a.forEach(z)}else o.fragment&&o.fragment.c();t.intro&&se(e.$$.fragment),ce(e,t.target,t.anchor,t.customElement),H()}N(c)}class de{$destroy(){fe(this,1),this.$destroy=I}$on(t,n){if(!X(n))return I;const r=this.$$.callbacks[t]||(this.$$.callbacks[t]=[]);return r.push(n),()=>{const l=r.indexOf(n);l!==-1&&r.splice(l,1)}}$set(t){this.$$set&&!x(t)&&(this.$$.skip_bound=!0,this.$$set(t),this.$$.skip_bound=!1)}}const be=\"\";function J(e,t,n){const r=e.slice();return r[11]=t[n],r[13]=n,r}function K(e){let t,n=e[11]+\"\",r,l,i,s;function g(){return e[9](e[13])}return{c(){t=k(\"button\"),r=A(n),l=S(),v(t,\"class\",\"mlu-quizquestion-option-button button svelte-fk6ar3\"),p(t,\"active\",e[5]===e[13]),p(t,\"correct-answer\",e[1]&&e[5]===e[13]&&e[2]==e[0].correctIndex),p(t,\"incorrect-answer\",e[1]&&e[5]===e[13]&&e[2]!=e[0].correctIndex),p(t,\"available\",e[4]&&e[1])},m(c,o){j(c,t,o),m(t,r),m(t,l),i||(s=Y(t,\"click\",g),i=!0)},p(c,o){e=c,o&1&&n!==(n=e[11]+\"\")&&T(r,n),o&32&&p(t,\"active\",e[5]===e[13]),o&39&&p(t,\"correct-answer\",e[1]&&e[5]===e[13]&&e[2]==e[0].correctIndex),o&39&&p(t,\"incorrect-answer\",e[1]&&e[5]===e[13]&&e[2]!=e[0].correctIndex),o&18&&p(t,\"available\",e[4]&&e[1])},d(c){c&&z(t),i=!1,s()}}}function U(e){let t;function n(i,s){return i[3]==!0?he:_e}let r=n(e),l=r(e);return{c(){l.c(),t=te()},m(i,s){l.m(i,s),j(i,t,s)},p(i,s){r!==(r=n(i))&&(l.d(1),l=r(i),l&&(l.c(),l.m(t.parentNode,t)))},d(i){l.d(i),i&&z(t)}}}function _e(e){let t;return{c(){t=k(\"p\"),t.textContent=\"This is not the correct answer. Try again!\",v(t,\"class\",\"svelte-fk6ar3\")},m(n,r){j(n,t,r)},d(n){n&&z(t)}}}function he(e){let t;return{c(){t=k(\"p\"),t.textContent=\"Good! You got the correct answer.\",v(t,\"class\",\"svelte-fk6ar3\")},m(n,r){j(n,t,r)},d(n){n&&z(t)}}}function me(e){let t,n,r=e[0].question+\"\",l,i,s,g,c,o,b=e[1]?\"Retry\":\"Submit\",a,q,y,h,C=e[0].options,d=[];for(let f=0;f<C.length;f+=1)d[f]=K(J(e,C,f));let _=e[1]&&U(e);return{c(){t=k(\"div\"),n=k(\"h2\"),l=A(r),i=S(),s=k(\"div\");for(let f=0;f<d.length;f+=1)d[f].c();g=S(),c=k(\"div\"),o=k(\"button\"),a=A(b),q=S(),_&&_.c(),v(n,\"class\",\"svelte-fk6ar3\"),v(s,\"class\",\"options svelte-fk6ar3\"),v(o,\"class\",\"submit-button svelte-fk6ar3\"),p(o,\"available\",!e[4]),v(c,\"class\",\"footer svelte-fk6ar3\"),v(t,\"class\",\"quiz-wrapper svelte-fk6ar3\")},m(f,w){j(f,t,w),m(t,n),m(n,l),m(t,i),m(t,s);for(let u=0;u<d.length;u+=1)d[u].m(s,null);m(t,g),m(t,c),m(c,o),m(o,a),m(c,q),_&&_.m(c,null),y||(h=Y(o,\"click\",e[10]),y=!0)},p(f,[w]){if(w&1&&r!==(r=f[0].question+\"\")&&T(l,r),w&311){C=f[0].options;let u;for(u=0;u<C.length;u+=1){const V=J(f,C,u);d[u]?d[u].p(V,w):(d[u]=K(V),d[u].c(),d[u].m(s,null))}for(;u<d.length;u+=1)d[u].d(1);d.length=C.length}w&2&&b!==(b=f[1]?\"Retry\":\"Submit\")&&T(a,b),w&16&&p(o,\"available\",!f[4]),f[1]?_?_.p(f,w):(_=U(f),_.c(),_.m(c,null)):_&&(_.d(1),_=null)},i:I,o:I,d(f){f&&z(t),ee(d,f),_&&_.d(),y=!1,h()}}}function pe(e,t,n){let{question:r={question:\"Who didn't attend this meeting?\",options:[\"Xin\",\"Anand\",\"Brent\"],correctIndex:2}}=t,l=!1,i=-1,s=\"no\",g=!1,c;function o(){n(4,g=!1),n(1,l=!1),n(2,i=-1),n(5,c=-1),n(3,s=\"no\")}function b(){n(1,l=!0),n(3,s=i==r.correctIndex)}function a(h){n(4,g=!0),n(2,i=h),n(5,c=h)}const q=h=>a(h),y=()=>l?o():b();return e.$$set=h=>{\"question\"in h&&n(0,r=h.question)},[r,l,i,s,g,c,o,b,a,q,y]}class ge extends de{constructor(t){super(),ae(this,t,pe,me,Z,{question:0})}}return ge}();\n",
       "</script>\n",
       "        \n",
       "        <div id=\"Quiz-e4eb746\"></div>\n",
       "        <script>\n",
       "        (() => {\n",
       "            var data = {\n",
       "\"question\": {\n",
       "\"question\": \"Which parameter in the `Model` class instantiation specifies the location of the finetuned LLM model artifact in an S3 bucket?\",\n",
       "\"options\": [\n",
       "\"image_uri\",\n",
       "\"model_data\",\n",
       "\"predictor_cls\",\n",
       "\"role\"\n",
       "],\n",
       "\"correctIndex\": 1\n",
       "}\n",
       "};\n",
       "            window.Quiz_data = data;\n",
       "            var Quiz_inst = new Quiz({\n",
       "                \"target\": document.getElementById(\"Quiz-e4eb746\"),\n",
       "                \"props\": data\n",
       "            });\n",
       "        })();\n",
       "        </script>\n",
       "        \n",
       "        "
      ],
      "text/plain": [
       "<mlu_utils.quiz_questions.Quiz at 0x7f32cd6e8ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlu_utils.quiz_questions import *\n",
    "lab4_question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac9808d-c770-4e32-850b-b18224225a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>var Quiz=function(){\"use strict\";var M=document.createElement(\"style\");M.textContent=`.quiz-wrapper.svelte-fk6ar3{padding:1rem}.footer.svelte-fk6ar3{display:flex;align-items:center}h2.svelte-fk6ar3{font-size:1.5rem;margin-bottom:2rem;color:#232f3e}p.svelte-fk6ar3{font-size:16px}.options.svelte-fk6ar3{display:grid;grid-template-columns:repeat(2,50%);grid-template-rows:repeat(2,1fr);width:100%;margin:auto;justify-content:center}.mlu-quizquestion-option-button.svelte-fk6ar3{padding:1rem;margin:.5rem}.submit-button.svelte-fk6ar3{padding:1rem;margin:.5rem;width:90px;color:#fff;background-color:coral}.active.svelte-fk6ar3{background-color:#232f3e;color:#fff}.correct-answer.svelte-fk6ar3{background-color:green}.incorrect-answer.svelte-fk6ar3{background-color:red;text-decoration:line-through}.available.svelte-fk6ar3{pointer-events:none;opacity:.6}\n",
       "`,document.head.appendChild(M);function I(){}function P(e){return e()}function W(){return Object.create(null)}function O(e){e.forEach(P)}function X(e){return typeof e==\"function\"}function Z(e,t){return e!=e?t==t:e!==t||e&&typeof e==\"object\"||typeof e==\"function\"}function x(e){return Object.keys(e).length===0}function m(e,t){e.appendChild(t)}function j(e,t,n){e.insertBefore(t,n||null)}function z(e){e.parentNode&&e.parentNode.removeChild(e)}function ee(e,t){for(let n=0;n<e.length;n+=1)e[n]&&e[n].d(t)}function k(e){return document.createElement(e)}function A(e){return document.createTextNode(e)}function S(){return A(\" \")}function te(){return A(\"\")}function Y(e,t,n,r){return e.addEventListener(t,n,r),()=>e.removeEventListener(t,n,r)}function v(e,t,n){n==null?e.removeAttribute(t):e.getAttribute(t)!==n&&e.setAttribute(t,n)}function ne(e){return Array.from(e.childNodes)}function T(e,t){t=\"\"+t,e.wholeText!==t&&(e.data=t)}function p(e,t,n){e.classList[n?\"add\":\"remove\"](t)}let L;function N(e){L=e}const $=[],D=[],Q=[],F=[],re=Promise.resolve();let B=!1;function oe(){B||(B=!0,re.then(H))}function R(e){Q.push(e)}const G=new Set;let E=0;function H(){if(E!==0)return;const e=L;do{try{for(;E<$.length;){const t=$[E];E++,N(t),le(t.$$)}}catch(t){throw $.length=0,E=0,t}for(N(null),$.length=0,E=0;D.length;)D.pop()();for(let t=0;t<Q.length;t+=1){const n=Q[t];G.has(n)||(G.add(n),n())}Q.length=0}while($.length);for(;F.length;)F.pop()();B=!1,G.clear(),N(e)}function le(e){if(e.fragment!==null){e.update(),O(e.before_update);const t=e.dirty;e.dirty=[-1],e.fragment&&e.fragment.p(e.ctx,t),e.after_update.forEach(R)}}const ie=new Set;function se(e,t){e&&e.i&&(ie.delete(e),e.i(t))}function ce(e,t,n,r){const{fragment:l,after_update:i}=e.$$;l&&l.m(t,n),r||R(()=>{const s=e.$$.on_mount.map(P).filter(X);e.$$.on_destroy?e.$$.on_destroy.push(...s):O(s),e.$$.on_mount=[]}),i.forEach(R)}function fe(e,t){const n=e.$$;n.fragment!==null&&(O(n.on_destroy),n.fragment&&n.fragment.d(t),n.on_destroy=n.fragment=null,n.ctx=[])}function ue(e,t){e.$$.dirty[0]===-1&&($.push(e),oe(),e.$$.dirty.fill(0)),e.$$.dirty[t/31|0]|=1<<t%31}function ae(e,t,n,r,l,i,s,g=[-1]){const c=L;N(e);const o=e.$$={fragment:null,ctx:[],props:i,update:I,not_equal:l,bound:W(),on_mount:[],on_destroy:[],on_disconnect:[],before_update:[],after_update:[],context:new Map(t.context||(c?c.$$.context:[])),callbacks:W(),dirty:g,skip_bound:!1,root:t.target||c.$$.root};s&&s(o.root);let b=!1;if(o.ctx=n?n(e,t.props||{},(a,q,...y)=>{const h=y.length?y[0]:q;return o.ctx&&l(o.ctx[a],o.ctx[a]=h)&&(!o.skip_bound&&o.bound[a]&&o.bound[a](h),b&&ue(e,a)),q}):[],o.update(),b=!0,O(o.before_update),o.fragment=r?r(o.ctx):!1,t.target){if(t.hydrate){const a=ne(t.target);o.fragment&&o.fragment.l(a),a.forEach(z)}else o.fragment&&o.fragment.c();t.intro&&se(e.$$.fragment),ce(e,t.target,t.anchor,t.customElement),H()}N(c)}class de{$destroy(){fe(this,1),this.$destroy=I}$on(t,n){if(!X(n))return I;const r=this.$$.callbacks[t]||(this.$$.callbacks[t]=[]);return r.push(n),()=>{const l=r.indexOf(n);l!==-1&&r.splice(l,1)}}$set(t){this.$$set&&!x(t)&&(this.$$.skip_bound=!0,this.$$set(t),this.$$.skip_bound=!1)}}const be=\"\";function J(e,t,n){const r=e.slice();return r[11]=t[n],r[13]=n,r}function K(e){let t,n=e[11]+\"\",r,l,i,s;function g(){return e[9](e[13])}return{c(){t=k(\"button\"),r=A(n),l=S(),v(t,\"class\",\"mlu-quizquestion-option-button button svelte-fk6ar3\"),p(t,\"active\",e[5]===e[13]),p(t,\"correct-answer\",e[1]&&e[5]===e[13]&&e[2]==e[0].correctIndex),p(t,\"incorrect-answer\",e[1]&&e[5]===e[13]&&e[2]!=e[0].correctIndex),p(t,\"available\",e[4]&&e[1])},m(c,o){j(c,t,o),m(t,r),m(t,l),i||(s=Y(t,\"click\",g),i=!0)},p(c,o){e=c,o&1&&n!==(n=e[11]+\"\")&&T(r,n),o&32&&p(t,\"active\",e[5]===e[13]),o&39&&p(t,\"correct-answer\",e[1]&&e[5]===e[13]&&e[2]==e[0].correctIndex),o&39&&p(t,\"incorrect-answer\",e[1]&&e[5]===e[13]&&e[2]!=e[0].correctIndex),o&18&&p(t,\"available\",e[4]&&e[1])},d(c){c&&z(t),i=!1,s()}}}function U(e){let t;function n(i,s){return i[3]==!0?he:_e}let r=n(e),l=r(e);return{c(){l.c(),t=te()},m(i,s){l.m(i,s),j(i,t,s)},p(i,s){r!==(r=n(i))&&(l.d(1),l=r(i),l&&(l.c(),l.m(t.parentNode,t)))},d(i){l.d(i),i&&z(t)}}}function _e(e){let t;return{c(){t=k(\"p\"),t.textContent=\"This is not the correct answer. Try again!\",v(t,\"class\",\"svelte-fk6ar3\")},m(n,r){j(n,t,r)},d(n){n&&z(t)}}}function he(e){let t;return{c(){t=k(\"p\"),t.textContent=\"Good! You got the correct answer.\",v(t,\"class\",\"svelte-fk6ar3\")},m(n,r){j(n,t,r)},d(n){n&&z(t)}}}function me(e){let t,n,r=e[0].question+\"\",l,i,s,g,c,o,b=e[1]?\"Retry\":\"Submit\",a,q,y,h,C=e[0].options,d=[];for(let f=0;f<C.length;f+=1)d[f]=K(J(e,C,f));let _=e[1]&&U(e);return{c(){t=k(\"div\"),n=k(\"h2\"),l=A(r),i=S(),s=k(\"div\");for(let f=0;f<d.length;f+=1)d[f].c();g=S(),c=k(\"div\"),o=k(\"button\"),a=A(b),q=S(),_&&_.c(),v(n,\"class\",\"svelte-fk6ar3\"),v(s,\"class\",\"options svelte-fk6ar3\"),v(o,\"class\",\"submit-button svelte-fk6ar3\"),p(o,\"available\",!e[4]),v(c,\"class\",\"footer svelte-fk6ar3\"),v(t,\"class\",\"quiz-wrapper svelte-fk6ar3\")},m(f,w){j(f,t,w),m(t,n),m(n,l),m(t,i),m(t,s);for(let u=0;u<d.length;u+=1)d[u].m(s,null);m(t,g),m(t,c),m(c,o),m(o,a),m(c,q),_&&_.m(c,null),y||(h=Y(o,\"click\",e[10]),y=!0)},p(f,[w]){if(w&1&&r!==(r=f[0].question+\"\")&&T(l,r),w&311){C=f[0].options;let u;for(u=0;u<C.length;u+=1){const V=J(f,C,u);d[u]?d[u].p(V,w):(d[u]=K(V),d[u].c(),d[u].m(s,null))}for(;u<d.length;u+=1)d[u].d(1);d.length=C.length}w&2&&b!==(b=f[1]?\"Retry\":\"Submit\")&&T(a,b),w&16&&p(o,\"available\",!f[4]),f[1]?_?_.p(f,w):(_=U(f),_.c(),_.m(c,null)):_&&(_.d(1),_=null)},i:I,o:I,d(f){f&&z(t),ee(d,f),_&&_.d(),y=!1,h()}}}function pe(e,t,n){let{question:r={question:\"Who didn't attend this meeting?\",options:[\"Xin\",\"Anand\",\"Brent\"],correctIndex:2}}=t,l=!1,i=-1,s=\"no\",g=!1,c;function o(){n(4,g=!1),n(1,l=!1),n(2,i=-1),n(5,c=-1),n(3,s=\"no\")}function b(){n(1,l=!0),n(3,s=i==r.correctIndex)}function a(h){n(4,g=!0),n(2,i=h),n(5,c=h)}const q=h=>a(h),y=()=>l?o():b();return e.$$set=h=>{\"question\"in h&&n(0,r=h.question)},[r,l,i,s,g,c,o,b,a,q,y]}class ge extends de{constructor(t){super(),ae(this,t,pe,me,Z,{question:0})}}return ge}();\n",
       "</script>\n",
       "        \n",
       "        <div id=\"Quiz-29375aca\"></div>\n",
       "        <script>\n",
       "        (() => {\n",
       "            var data = {\n",
       "\"question\": {\n",
       "\"question\": \"What does 'image_uri' represent in deplopying a model to an endpoint using Sagemaker?\",\n",
       "\"options\": [\n",
       "\"The docker image URI representing the deep learning framework and version to be used\",\n",
       "\"The location where the model artifacts are stored in the S3 bucket\",\n",
       "\"The name of the instance that would host the deployed model\",\n",
       "\"The version of the model that will be deployed.\"\n",
       "],\n",
       "\"correctIndex\": 0\n",
       "}\n",
       "};\n",
       "            window.Quiz_data = data;\n",
       "            var Quiz_inst = new Quiz({\n",
       "                \"target\": document.getElementById(\"Quiz-29375aca\"),\n",
       "                \"props\": data\n",
       "            });\n",
       "        })();\n",
       "        </script>\n",
       "        \n",
       "        "
      ],
      "text/plain": [
       "<mlu_utils.quiz_questions.Quiz at 0x7f32cd6e87f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab4_question2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f03997-8d4c-41ec-ae4d-666eca8e037b",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "\n",
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
